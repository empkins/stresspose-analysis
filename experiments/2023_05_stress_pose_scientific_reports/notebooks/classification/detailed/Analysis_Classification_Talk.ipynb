{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Classification Results â€“ TSST vs. f-TSST (Talk Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from fau_colors import cmaps, register_fausans_font\n",
    "\n",
    "import biopsykit as bp\n",
    "from biopsykit.classification.model_selection import SklearnPipelinePermuter\n",
    "from biopsykit.classification.analysis import (\n",
    "    predictions_as_df,\n",
    "    predict_proba_from_estimator,\n",
    "    plot_conf_matrix,\n",
    "    plot_conf_matrix_proba,\n",
    ")\n",
    "\n",
    "from stresspose_analysis.dataset import StressPoseDataset\n",
    "from stresspose_analysis.classification.utils import (\n",
    "    feature_data_long_to_wide,\n",
    "    get_feature_counts,\n",
    "    feature_counts_to_latex,\n",
    "    get_number_features_per_fold,\n",
    ")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_fausans_font()\n",
    "plt.close(\"all\")\n",
    "\n",
    "palette = sns.color_palette(cmaps.faculties)\n",
    "sns.set_theme(context=\"notebook\", style=\"ticks\", palette=palette)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"mathtext.default\"] = \"regular\"\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"FAUSans Office\"\n",
    "\n",
    "\n",
    "palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_type = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(\"../../../config.json\")\n",
    "config_dict = json.load(config_path.open(encoding=\"utf-8\"))\n",
    "\n",
    "base_path = Path(config_dict[deploy_type][\"base_path\"])\n",
    "dataset = StressPoseDataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\"tsst\": \"TSST\", \"ftsst\": \"f-TSST\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_type = \"cumulative_time_5min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"../../../\")\n",
    "input_path = root_path.joinpath(\"output/classification/detailed\")\n",
    "output_path = root_path.joinpath(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = output_path.joinpath(\"plots\")\n",
    "\n",
    "bp.utils.file_handling.mkdirs([img_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_files = sorted(input_path.glob(f\"*_{classification_type}_*.pkl\"))\n",
    "feature_files = sorted(input_path.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "pickle_file = pickle_files[index]\n",
    "feature_file = feature_files[index]\n",
    "\n",
    "print(\"Selected Files:\")\n",
    "print(f\"{pickle_file.name}\")\n",
    "print(f\"{feature_file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickled `SklearnPipelinePermuter` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_permuter = SklearnPipelinePermuter.from_pickle(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bp.io.load_long_format_csv(feature_file)\n",
    "data = data.rename(index=label_mapping, level=\"condition\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wide = feature_data_long_to_wide(data, index_levels_out=[\"subject\", \"condition\"])\n",
    "data_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of all relevant metrics (performance scores, confusion matrix, true and predicted labels) of the **best pipelines** for each fold (i.e., the `best_estimator_` parameter of each inner `cv` object), evaluated for each evaluated pipeline combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_summary = pipeline_permuter.metric_summary(additional_metrics=[\"f1_score\", \"precision\"], pos_label=\"tsst\")\n",
    "metric_summary = metric_summary.sort_values(by=\"mean_test_accuracy\", ascending=False)\n",
    "metric_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Pipeline per Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clfs = metric_summary.groupby(\"pipeline_clf\", group_keys=False).apply(\n",
    "    lambda df: df.sort_values(by=\"mean_test_accuracy\", ascending=False).iloc[[0]]\n",
    ")\n",
    "best_clfs = best_clfs.sort_values(by=\"mean_test_accuracy\", ascending=False)\n",
    "best_clfs = best_clfs.droplevel(level=\"pipeline_remove_var\")\n",
    "best_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = pipeline_permuter.metric_summary_to_latex(\n",
    "    data=best_clfs,\n",
    "    pipeline_steps=[\"pipeline_scaler\", \"pipeline_reduce_dim\", \"pipeline_clf\"],\n",
    "    clines=None,\n",
    "    sparse_index=False,\n",
    "    highlight_best=True,\n",
    "    caption=r\"Mean $\\pm$ standard deviation of classification performance metrics over the 5-fold model evaluation CV. For each evaluated classifier, the classification pipeline combination with the highest mean accuracy is shown. The classification pipelines scoring the highest metrics are highlighted in \\textbf{bold}.\",\n",
    "    label=\"tab:classification_results\",\n",
    ")\n",
    "# some dirty manual postprocessing of output\n",
    "latex_output = re.sub(r\"\\\\cline{1-4} \\\\cline{2-4}\\n\\\\bottomrule\", r\"\\\\bottomrule\", latex_output)\n",
    "latex_output = re.sub(r\"\\\\cline{1-4} \\\\cline{2-4}\", r\"\\\\cline{1-4}\", latex_output)\n",
    "latex_output = re.sub(\n",
    "    r\"{} & {} & {}\", r\"{Scaler} & {\\\\makecell[lc]{Feature\\\\\\\\ Selection}} & {Classifier}\", latex_output, count=1\n",
    ")\n",
    "latex_output = re.sub(\n",
    "    r\"{Scaler} & {\\\\makecell\\[lc\\]{Feature\\\\\\\\ Selection}} & {Classifier} & {} & {} & {} \\\\\\\\\\n\", r\"\", latex_output\n",
    ")\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pipeline = (\"VarianceThreshold\", \"MinMaxScaler\", \"RFE\", \"SVC\")\n",
    "\n",
    "labels = [\"TSST\", \"f-TSST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_summary = pipeline_permuter.best_estimator_summary()\n",
    "best_estimator_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = predictions_as_df(pipeline_permuter, data_wide, selected_pipeline, label_mapping)\n",
    "\n",
    "predictions = predictions.join(dataset.condition_first).join(dataset.cortisol_non_responder)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "plot_conf_matrix(predictions, labels, label_name=\"condition\", ax=ax)\n",
    "fig.tight_layout(pad=0)\n",
    "\n",
    "fig.savefig(img_path.joinpath(\"img_confusion_matrix_talk_only.pdf\"), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix by Condition Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 3), ncols=2)\n",
    "\n",
    "for (key, df), ax in zip(predictions.groupby(\"condition_first\"), axs):\n",
    "    plot_conf_matrix(df, labels, label_name=\"condition\", ax=ax)\n",
    "    ax.set_title(key)\n",
    "\n",
    "fig.tight_layout(pad=0, w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix by Cortisol Non-Responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 3), ncols=2)\n",
    "\n",
    "for (key, df), ax in zip(predictions.groupby(\"non_responder\"), axs):\n",
    "    plot_conf_matrix(df, labels, ax=ax)\n",
    "    ax.set_title(f\"Non-Responder: {key}\")\n",
    "\n",
    "fig.tight_layout(pad=0, w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_proba = predict_proba_from_estimator(\n",
    "    pipeline_permuter, data_wide, selected_pipeline, label_col=\"condition\", column_names=label_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "\n",
    "plot_conf_matrix_proba(predictions_proba, labels=labels, label_col=\"condition\", ax=ax)\n",
    "\n",
    "fig.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_proba_cond = predictions_proba.join(dataset.condition_first).join(dataset.cortisol_non_responder)\n",
    "predictions_proba_cond = predictions_proba_cond.set_index([\"condition_first\", \"non_responder\"], append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Probability by Condition Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 3), ncols=2)\n",
    "\n",
    "for (key, df), ax in zip(predictions_proba_cond.groupby(\"condition_first\"), axs):\n",
    "    plot_conf_matrix_proba(df, labels=labels, label_col=\"condition\", ax=ax)\n",
    "    ax.set_title(key)\n",
    "\n",
    "fig.tight_layout(w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Probability by Cortisol Non-Responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 3), ncols=2)\n",
    "\n",
    "for (key, df), ax in zip(predictions_proba_cond.groupby(\"non_responder\"), axs):\n",
    "    plot_conf_matrix_proba(df, labels=labels, label_col=\"condition\", ax=ax)\n",
    "    ax.set_title(f\"Non-Responder: {key}\")\n",
    "\n",
    "fig.tight_layout(w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of features selected by the feature selection algorithm\n",
    "num_features_per_fold = get_number_features_per_fold(pipeline_permuter, selected_pipeline)\n",
    "num_features_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_counts = get_feature_counts(pipeline_permuter, data=data, pipeline=selected_pipeline, num_features=1)\n",
    "feature_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Number of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_features = pd.DataFrame(feature_counts.groupby(\"feature_type\").size(), columns=[\"Count\"]).T\n",
    "number_features[\"total\"] = [len(feature_counts)]\n",
    "\n",
    "number_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaTeX table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts_export = feature_counts[feature_counts[\"Count\"] >= 3]\n",
    "\n",
    "caption = r\"Overview of features that were selected by the RFE feature selection algorithm in at least 3 out of 5 CV folds.\\\\\\textit{Note:} Stat. Per. = Static Periods.\"\n",
    "label = \"tab:feature_counts\"\n",
    "feature_counts_tex = feature_counts_to_latex(feature_counts_export, caption=caption, label=label)\n",
    "# tab_path_paper.joinpath(\"tab_feature_counts.tex\").open(mode=\"w+\").write(feature_counts_tex)\n",
    "print(feature_counts_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_extremities = [\"RightHand\", \"LeftForeArm\", \"RightForeArm\"]\n",
    "trunk = [\"Spine3\"]\n",
    "head = [\"Head\"]\n",
    "\n",
    "feature_counts_body_part = feature_counts.groupby(\"body_part\").size().sort_values(ascending=False)\n",
    "feature_counts_body_part = pd.DataFrame(feature_counts_body_part, columns=[\"Counts\"])\n",
    "\n",
    "print(f\"Upper Extremities: {feature_counts_body_part.loc[upper_extremities].sum().sum()}\")\n",
    "print(f\"Trunk: {feature_counts_body_part.loc[trunk].sum().sum()}\")\n",
    "print(f\"Head: {feature_counts_body_part.loc[head].sum().sum()}\")\n",
    "\n",
    "feature_counts_body_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_plot = feature_counts.iloc[0:5].index\n",
    "data_unstack = data[\"data\"].unstack([\"subject\", \"condition\"]).T\n",
    "data_plot = data_unstack.loc[:, features_plot]\n",
    "data_plot.columns = [\"-\".join(col) for col in data_plot.columns]\n",
    "\n",
    "pairgrid, features = bp.plotting.feature_pairplot(data=data_plot, hue=\"condition\")\n",
    "display(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empkins_d03_macro_analysis",
   "language": "python",
   "name": "empkins_d03_macro_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
